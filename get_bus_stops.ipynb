{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import folium\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.cluster.hierarchy import linkage, cut_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import overpy\n",
    "import os\n",
    "import alphashape\n",
    "import shapely\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlIANie4duW6"
   },
   "source": [
    "## 1.1.Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNNljMQEhCLb"
   },
   "source": [
    "Using [Overpass API](https://wiki.openstreetmap.org/wiki/Overpass_API) to query locations that fulfill the given conditions. In this case, all [amenities](https://wiki.openstreetmap.org/wiki/Key:amenity), but all bus stations could be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBeZAYgGADT2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "api = overpy.Overpass()\n",
    "\n",
    "location = \"Granada\"\n",
    "road_distance = \"2000\"  # (m)\n",
    "\n",
    "query = '''\n",
    "[out:json];\n",
    "area[name='''+ location + '''][admin_level=8]->.where;\n",
    "node(area.where)[highway=bus_stop];\n",
    "out body;\n",
    ">;\n",
    "out skel qt;'''\n",
    "\n",
    "\n",
    "# Selecting ALL amenities\n",
    "query = '''\n",
    "[out:json];\n",
    "area[name='''+ location + '''][admin_level=8]->.granada;\n",
    "(\n",
    "  node(area.granada)[amenity](37.120, -3.650, 37.300, -3.570);\n",
    ");\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "'''\n",
    "\n",
    "response = api.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKi9abgfAGrA",
    "outputId": "5b003261-57f6-4e19-eb38-5b9ab5418d39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the dataframe [id,latitude,longitude]\n",
    "df = pd.DataFrame(\n",
    "    columns=[\"id\",\"lat\",\"lon\"])\n",
    "\n",
    "for node in response.get_nodes():\n",
    "    # Adding all the position information of nodes\n",
    "    new_row = pd.DataFrame(\n",
    "        {\"id\": node.id,\n",
    "         \"lat\": node.lat,\n",
    "         \"lon\": node.lon},\n",
    "         index=[0])\n",
    "\n",
    "    df = pd.concat([df,new_row],axis=0)\n",
    "\n",
    "# Formatted information into a DataFrame, only for convenience\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "iBk7o1rHAJFc",
    "outputId": "2efc102b-dac3-4cc2-8b6e-6baf62eff3db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=df[\"lon\"],y=df[\"lat\"], s=0.5)\n",
    "plt.xlabel(\"lon\")\n",
    "plt.ylabel(\"lat\")\n",
    "print(\"Number of detected possible places:\", len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyxD_Ly-dyzY"
   },
   "source": [
    "## 1.2.Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvEfK9Vk-8UA"
   },
   "source": [
    "Preprocessing: We will be using a clustering algorithm to hierarchically organize the bus stations. So the QUBO can be implemented layer by layer in the same hierarchical approach. This way, we exploit the fractal network that bus stops are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1.Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a class with all desirrd functionalities implemented and some functions that return distance matrices, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "class linkageCut:\n",
    "    def __init__(self, df):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.data = self.scaler.fit_transform(df[['lon','lat']].values)\n",
    "        self.data_lon_lat = df[['lon','lat']].values\n",
    "        self.linkage_matrix = linkage(self.data, method='ward')\n",
    "        self.tree_cut = cut_tree(self.linkage_matrix)\n",
    "        \n",
    "        self.top_down = None\n",
    "        self.distance_matrix = None\n",
    "        self.n_clusters = None\n",
    "    def give_tree_cut(self):\n",
    "        return self.tree_cut\n",
    "    \n",
    "    def __nunique(self, a, axis):\n",
    "        ''' Count the number of unique elements in an array and axis'''\n",
    "        return (np.diff(np.sort(a,axis=axis),axis=axis)!=0).sum(axis=axis)+1\n",
    "\n",
    "    def __recursive_down(self, n_clusters, level, total_levels, mask):\n",
    "        if len(str(level)) < total_levels:\n",
    "            \n",
    "            # Selecting specific parent cluster\n",
    "            small_tree = self.tree_cut[mask]\n",
    "            \n",
    "            # Checking how many subclusters there are in the parent cluster for each step in\n",
    "            # the clustering (ward) process\n",
    "            small_tree_nclusters = self.__nunique(small_tree, axis=0)\n",
    "            \n",
    "            try:\n",
    "                # This is the step where there are exactly n_clusters subclusters\n",
    "                sub_tree_step = np.where(small_tree_nclusters == n_clusters)[0][-1]\n",
    "            except:\n",
    "                raise Exception(\"Some cluster cannot be further divided\")\n",
    "            # Now we truly have the subdivision\n",
    "            \n",
    "            counter = 1\n",
    "            for sub_lbl in np.unique(small_tree[:,sub_tree_step]):\n",
    "                # Now we prepare the mask for each subcluster and the recursion\n",
    "                sub_data_mask = np.where(self.tree_cut[:, sub_tree_step] == sub_lbl)[0]\n",
    "                write = self.__recursive_down( \n",
    "                                   n_clusters, int(str(level) + str(counter)), total_levels,\n",
    "                                   sub_data_mask)\n",
    "                if write == None:\n",
    "                    write = str(level) + str(counter)\n",
    "                self.top_down[sub_data_mask, len(str(level))] = int(write)\n",
    "                counter+=1\n",
    "                \n",
    "            return None\n",
    "        else:\n",
    "            return level\n",
    "        \n",
    "    def top_down_view_recur(self, n_clusters, levels=1):\n",
    "        ''' Constructs a top down view in which each cluster is\n",
    "        subsequently divided in 'n_clusters'. This process \n",
    "        is iterated 'level' times.\n",
    "        In each step, all data is labelled accordingly.\n",
    "        \n",
    "        The naming conventions for the labels is 1,2, ..., n_clusters for \n",
    "        the first level, 11 for the first subcluster of cluster 1 and so on. Example:\n",
    "        \n",
    "        132 has 3 levels, in the order 1(top)-3(middle)-2(lowest)\n",
    "        \n",
    "        Obviously, the maximum n_clusters is 9 for our proof of concept, for larger values, \n",
    "        char implementations should be considered\n",
    "        \n",
    "        :input n_clusters: number of clusters per level\n",
    "        :input levels: number of layers or levels\n",
    "        :return: (len_data)X(level) matrix with labels\n",
    "        '''\n",
    "        self.n_clusters = n_clusters\n",
    "        # First level\n",
    "        if levels < 1:\n",
    "            raise Exception(\"levels must be >= 1\") \n",
    "        \n",
    "        self.top_down = np.zeros((len(self.data), levels))\n",
    "        \n",
    "        # The first level is, by definition, in the tree_cut indx\n",
    "        # len_data - n_clusters \n",
    "        tree_step = len(self.tree_cut) - n_clusters\n",
    "        first_lbls = np.unique(self.tree_cut[:, tree_step])\n",
    "        \n",
    "        # Second level\n",
    "        for lbl in first_lbls:\n",
    "            data_mask = np.where(self.tree_cut[:, tree_step] == lbl)[0]\n",
    "            self.top_down[data_mask, 0] = lbl + 1\n",
    "            self.__recursive_down(n_clusters, lbl + 1, levels, data_mask)\n",
    "            \n",
    "        return self.top_down\n",
    "    def give_center_label(self, label):\n",
    "        ''' Returns the positions in lon-lat space of the centers with a given label.\n",
    "        \n",
    "        Examples: \n",
    "        give_centers_label(11) returns the centroid \"11\"\n",
    "        '''\n",
    "        level = len(str(int(label))) - 1\n",
    "        sub_top_down = self.top_down[:, level]\n",
    "        cluster_mask = sub_top_down == label\n",
    "        \n",
    "        center = np.mean(self.data[cluster_mask], axis=0)\n",
    "        # Find the closest location\n",
    "        center = self.data[cluster_mask][\n",
    "            np.argmin(euclidean_distances(self.data[cluster_mask], center.reshape(1,-1)))]\n",
    "        \n",
    "        return center\n",
    "    \n",
    "    def give_centers_level(self, level):\n",
    "        ''' Return the possible location closer to the cluster centroid in a certain level'''\n",
    "        \n",
    "        if type(self.top_down) != np.ndarray:\n",
    "            print(\"You must first execute top_down_view_recur first\")\n",
    "        else:\n",
    "            if level > self.top_down.shape[1]:\n",
    "                print('Level out of bounds')\n",
    "            else:     \n",
    "                # Calculate the centers in normalized space and return to lon-lat\n",
    "                sub_top_down = self.top_down[:,level]\n",
    "                level_labels = np.unique(sub_top_down)\n",
    "                centers = np.zeros((len(level_labels),2))\n",
    "                \n",
    "                for i in range(len(level_labels)):\n",
    "                    centers[i] = self.give_center_label(level_labels[i])\n",
    "                    \n",
    "                centers = self.scaler.inverse_transform(centers)\n",
    "            return centers    \n",
    "        \n",
    "    def give_centers_label_down(self, label):\n",
    "        ''' Return the centers locations from a label down in order: 11, 12, 13, 14\n",
    "        Example: give_centers_label_down(2) returns the position of stops corresponding to 21, 22, 23,...\n",
    "        '''\n",
    "        level = len(str(int(label))) - 1\n",
    "        if type(self.top_down) != np.ndarray:\n",
    "            print(\"You must first execute top_down_view_recur first\")\n",
    "        else:\n",
    "            if level > self.top_down.shape[1]:\n",
    "                print('Level out of bounds')\n",
    "            else:     \n",
    "                # Calculate the centers in normalized space and return to lon-lat\n",
    "                sub_top_down = self.top_down[:,level+1]\n",
    "                \n",
    "                # Checking upper level\n",
    "                sub_top_down = sub_top_down[(sub_top_down/10).astype(int) == label] \n",
    "                level_labels = np.unique(sub_top_down)\n",
    "                centers = np.zeros((self.n_clusters,2))\n",
    "                \n",
    "                for i in range(len(level_labels)):\n",
    "                    centers[i] = self.give_center_label(level_labels[i])\n",
    "                    \n",
    "                centers = self.scaler.inverse_transform(centers)\n",
    "            return centers    \n",
    "    def __OSRM_query(self, coords, sources=None, destinations=None):\n",
    "        url = \"http://router.project-osrm.org/table/v1/driving/\"\n",
    "        routes = \"\"\n",
    "\n",
    "        # Query with longitude1,latitude1;longitude2,latitude2;...\n",
    "        for cl_ in coords:\n",
    "            routes += str(cl_[0])+\",\"+str(cl_[1])+\";\"\n",
    "        routes = routes[:-1]\n",
    "        dir_query = url+routes+\"?annotations=distance\"\n",
    "        \n",
    "        if (sources==None) & (destinations==None):\n",
    "            pass\n",
    "        else:\n",
    "            if (sources!=None):\n",
    "                dir_query +='&sources='\n",
    "                for indx in sources:\n",
    "                    dir_query += str(indx) + ';'\n",
    "                dir_query = dir_query[:-1]\n",
    "            if (destinations!=None):\n",
    "                dir_query +='&destinations='\n",
    "                for indx in destinations:\n",
    "                    dir_query += str(indx) + ';'\n",
    "                dir_query = dir_query[:-1]\n",
    "                \n",
    "        routes_response = requests.get(dir_query)\n",
    "        dist_table_json = routes_response.json()\n",
    "        try:\n",
    "            dist_matrix=np.array(dist_table_json[\"distances\"])/1000 # meters to km\n",
    "            return dist_matrix\n",
    "        except:\n",
    "            print(\"Something broken with OSRM\")\n",
    "        \n",
    "    def dist_matrix_level(self, level, return_labels=True):    \n",
    "        ''' Returns the distance matrix for all center clusters in a given level'''\n",
    "        centers_obj = self.give_centers_level(level)\n",
    "        dist_matrix = self.__OSRM_query(centers_obj)\n",
    "        dist_matrix += dist_matrix.T\n",
    "        ind_labels = np.array(range(1,len(centers_obj) + 1))\n",
    "        \n",
    "        if return_labels:\n",
    "            return dist_matrix, ind_labels\n",
    "        else:\n",
    "            return dist_matrix\n",
    "        \n",
    "    def dist_matrix_label_down(self, label, connections=[], return_labels=True):\n",
    "        ''' Returns the distance matrix of a single cluster divided under a certain level\n",
    "        given by the label returned by top_down_view_recur, with the \n",
    "        connected nodes (if there are any), in the first and last position of the array.\n",
    "        The connections must be the other clusters connected in the upper level.\n",
    "        \n",
    "        Cases\n",
    "        (i) No assumptions about higher level connection (connected_clusters=None). Returns the distance array \n",
    "        without any particular ordering\n",
    "        (ii) Only one element in connected_cluster. It is placed in the first index of the distance array\n",
    "        (iii) Two elements in connected_cluster. They are placed in the first and last indices of the distance array\n",
    "        \n",
    "        Examples:\n",
    "        \n",
    "        dist_array(1, connections = [2,3]) would assign the closest stops from 1 (from 11, 12, ...) to \n",
    "        2 and 3 (21,22,23... and 31,32,33...) as first and last stops to ensure a smooth 2-1-3 route.\n",
    "                \n",
    "        :return:\n",
    "        '''\n",
    "        \n",
    "        level = str(int(label))\n",
    "        clusters_obj = self.give_centers_label_down(label)\n",
    "        ind_labels = np.array(range(1,len(clusters_obj) + 1))\n",
    "            \n",
    "        if len(connections) == 0:\n",
    "            print('none')\n",
    "        else:\n",
    "            clusters_conn_1 = self.give_centers_label_down(connections[0])\n",
    "            coords_obj1 = np.append(clusters_obj, clusters_conn_1, axis=0)\n",
    "            ins = range(len(clusters_obj))\n",
    "            outs = range(len(clusters_obj), len(clusters_obj) + len(clusters_conn_1))\n",
    "            \n",
    "            # Bidirectional matrix\n",
    "            dist_obj1 = self.__OSRM_query(coords_obj1, sources=ins, destinations=outs)\n",
    "            dist_obj1 += self.__OSRM_query(coords_obj1, sources=outs, destinations=ins).T\n",
    "            \n",
    "            if len(connections) == 2:\n",
    "                clusters_conn_2 = self.give_centers_label_down(connections[0])\n",
    "                coords_obj2 = np.append(clusters_obj, clusters_conn_2, axis=0)\n",
    "                ins = range(len(clusters_obj))\n",
    "                outs = range(len(clusters_obj), len(clusters_obj) + len(clusters_conn_2))\n",
    "            \n",
    "                # Bidirectional matrix\n",
    "                dist_obj2 = self.__OSRM_query(coords_obj2, sources=ins, destinations=outs)\n",
    "                dist_obj2 += self.__OSRM_query(coords_obj2, sources=outs, destinations=ins)\n",
    "                min_dist_indx_2 = np.unravel_index(np.argmin(dist_obj2), dist_obj2.shape)[0]\n",
    "                \n",
    "                #Swaping places\n",
    "                \n",
    "                ind_labels[[min_dist_indx_2, -1]] = ind_labels[[-1, min_dist_indx_2]]\n",
    "                clusters_obj[[min_dist_indx_2, -1]] = clusters_obj[[-1, min_dist_indx_2]]\n",
    "            \n",
    "                \n",
    "            min_dist_indx_1 = np.unravel_index(np.argmin(dist_obj1), dist_obj1.shape)[0]\n",
    "            # Swapping places\n",
    "            ind_labels[[min_dist_indx_1, 0]] = ind_labels[[0, min_dist_indx_1]]\n",
    "            clusters_obj[[min_dist_indx_1, 0]] = clusters_obj[[0, min_dist_indx_1]]\n",
    "            print(ind_labels)\n",
    "        \n",
    "        dist_matrix = self.__OSRM_query(clusters_obj)\n",
    "        dist_matrix += dist_matrix.T\n",
    "        \n",
    "        ind_labels += 10*label # Adding prefix to label\n",
    "        print(min_dist_indx_1, min_dist_indx_2)\n",
    "        if return_labels:\n",
    "            return dist_matrix, ind_labels\n",
    "        else:\n",
    "            return dist_matrix\n",
    "            \n",
    "\n",
    "linkage_matrix = linkageCut(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to apply a hierarchical cluster (Ward distances) and classify all fetched possible \n",
    "locations into all clusters. W want a recursively defined structure: N 0-level districts, N 1-level sub-districts\n",
    "per district. The function top_down_view achieves that exact classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clusters = 6  \n",
    "levels = 2\n",
    "\n",
    "# We hierarchically distribute all points\n",
    "top_down = linkage_matrix.top_down_view_recur(n_clusters, levels)\n",
    "X = linkage_matrix.data\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((5,5))\n",
    "\n",
    "agg_labels = top_down[:,0] # level 0\n",
    "ax.scatter(X.T[0], X.T[1], c=agg_labels)\n",
    "ax.set_title(f'Ward clustering, level 0: {n_clusters} clusters ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see how each cluster in the previous figure is subsequently divided in N clusters. The tiny variations in hue indicate the different level-1 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_labels = top_down[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X.T[0], X.T[1], c=agg_labels)\n",
    "ax.set_title(f'Ward clustering, level 1: {n_clusters*n_clusters} clusters ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our location for the bus trajectory, we will use the actual amenity closer to the centroid of \n",
    "each cluster centroid (per level as well). The result is presented in the next figure with red lines that\n",
    "represent approximately the limits for level-0 clusters. The colors indicate level-1 clusters and the crosses the \n",
    "corresponding centroid locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fancy scatter\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((5,5))\n",
    "X = np.array(linkage_matrix.data_lon_lat, dtype=np.float64)\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], c=top_down[:,1]%10, cmap='Accent')\n",
    "alpha_list = np.ones(n_clusters)*100\n",
    "\n",
    "for i in range(1,n_clusters+1):\n",
    "    cluster = X[top_down[:,0] == i]\n",
    "    alpha = alpha_list[i-1]\n",
    "    hull = alphashape.alphashape(cluster, alpha)\n",
    "    if type(hull)== shapely.geometry.multipolygon.MultiPolygon:\n",
    "        areas = [ geom.area for geom in hull.geoms]\n",
    "        # Select the component with larger area\n",
    "        big = np.argmax(areas)\n",
    "        hull_pts = hull.geoms[big].exterior.coords.xy\n",
    "    else:\n",
    "        hull_pts = hull.exterior.coords.xy\n",
    "    poly_patch = Polygon(np.array(hull_pts).T, facecolor='none', edgecolor='red')\n",
    "    ax.add_patch(poly_patch)\n",
    "\n",
    "centers =  linkage_matrix.give_centers_level(0)\n",
    "plt.scatter(*centers.T, marker='X', edgecolors='black', color='red', linewidth=0.5, label='level 0')\n",
    "centers =  linkage_matrix.give_centers_level(1)\n",
    "plt.scatter(*centers.T, marker='X', edgecolors='black', linewidth=0.5, label='level 1')    \n",
    "fig.suptitle('Hierarchical division')\n",
    "\n",
    "plt.xlabel(r'lon (deg)')\n",
    "plt.ylabel(r'lat (deg)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuPSRXwMd4s3"
   },
   "source": [
    "## 1.3. Locations in the map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the bus stops in their real geographical location. To do that, we use folium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "WdqqbbWtX2J6",
    "outputId": "9ab16af1-534d-420c-bd5e-f19ec7b4510d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_show_array(data, labels, loc_coords, color, map=None):\n",
    "\n",
    "  # Create a map centered on loc_coords [latitude, longitude]\n",
    "  if map == None:\n",
    "      map = folium.Map(location=loc_coords, zoom_start=12)\n",
    "\n",
    "  # Loop through the data and add markers for each location\n",
    "  for i in range(len(data)):\n",
    "      folium.Marker([data[i][1], data[i][0]],\n",
    "                    popup=labels[i], icon=folium.Icon(color=color) ).add_to(map)\n",
    "  return map\n",
    "\n",
    "centers_0 =  linkage_matrix.give_centers_level(0)\n",
    "means = centers_0.mean(axis=0)\n",
    "means_lat_lon = [means[1], means[0]]\n",
    "labels_0 = range(1, len(centers_0) + 1)\n",
    "map = map_show_array(centers_0, labels, means_lat_lon, 'red')\n",
    "\n",
    "centers_1 =  linkage_matrix.give_centers_level(1)\n",
    "means = centers_1.mean(axis=0)\n",
    "means_lat_lon = [means[1], means[0]]\n",
    "labels = [ int(str(i) + str(j)) for i in labels_0 for j in labels_0] \n",
    "print(labels)\n",
    "map_show_array(centers_1, labels, means_lat_lon, 'blue', map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Solve with QUBOSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE EXECUTE QUBOSOLVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualize QUBOSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_data(df, labels, n_sampled_stops, seed = 140421):\n",
    "  np.random.seed(seed)\n",
    "  # We extract n samples from each cluster\n",
    "  unique_labels = np.unique(labels)\n",
    "  # first position is reserved for nonassigned data\n",
    "  n_cluster = np.zeros(len(unique_labels))\n",
    "  indices = np.indices(labels.shape)[0]\n",
    "  cluster_indices = []\n",
    "  max_cluster_size = int(n_sampled_stops/len(unique_labels))\n",
    "\n",
    "  sample_indx = []\n",
    "\n",
    "  for i in range(len(unique_labels)):\n",
    "    filter_labels = labels == unique_labels[i]\n",
    "    cluster_indices = indices[filter_labels]\n",
    "    n_cluster[i] = len(cluster_indices)\n",
    "\n",
    "    # Now we sample max_cluster_size\n",
    "    extract_size = np.amin([max_cluster_size, n_cluster[i]]).astype(int)\n",
    "    sample_indx.extend(np.random.choice(cluster_indices, size=extract_size, replace=False))\n",
    "  final_data = pd.DataFrame(df.to_numpy()[sample_indx], columns=['id', 'lat', 'lon', 'index'])\n",
    "  return final_data\n",
    "\n",
    "# Since calculating driving distances is a costly process, we sample the data to obtain \n",
    "# something manageable\n",
    "labels = top_down[:,0]\n",
    "df['index'] = range(1, len(df) + 1)\n",
    "n_sampled_stops = 100\n",
    "final_data = sample_data(df, labels, n_sampled_stops)\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(df, line, color, map=None):\n",
    "    means = df.mean()\n",
    "    loc_coords = [means.iloc[1], means.iloc[2]]\n",
    "    if map == None:\n",
    "        map = folium.Map(location=loc_coords, zoom_start=8)\n",
    "    # Get all connected positions from line adj matrix\n",
    "    nonzero = np.nonzero(line)\n",
    "    for i in range(len(nonzero[0])):\n",
    "        indx1 = nonzero[0][i]\n",
    "        indx2 = nonzero[1][i]\n",
    "\n",
    "        pos_1 = df.iloc[indx1][['lat','lon']].values\n",
    "        pos_2 = df.iloc[indx2][['lat','lon']].values\n",
    "        folium.Marker(pos_1).add_to(map)\n",
    "        folium.Marker(pos_2).add_to(map)\n",
    "        colorline = folium.features.PolyLine([pos_1,pos_2], color=color)\n",
    "        colorline.add_to(map)\n",
    "    return map\n",
    "line = np.genfromtxt(os.path.join(\"results\", 'Line0.dat'))\n",
    "map = draw_line(final_data, line, 'red')\n",
    "line = np.genfromtxt(os.path.join(\"results\", 'Line1.dat'))\n",
    "map = draw_line(final_data, line, 'blue', map)\n",
    "line = np.genfromtxt(os.path.join(\"results\", 'Line2.dat'))\n",
    "map = draw_line(final_data, line, 'green', map)\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
