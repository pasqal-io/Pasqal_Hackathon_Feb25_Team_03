{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to execute this notebook, make sure you have already installed the necessary requirements described in the README.md.\n",
    "The following are all the necessary imports to run the entire notebook, from start to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from main.tree.linkageTree import linkageCut\n",
    "from main.tsp.TSP_Formulation_Methods import ( \n",
    "    create_QUBO_matrix,\n",
    "    solve_qubo_with_Dwave,\n",
    "    check_solution,\n",
    "    check_solution_return,\n",
    "    load_lambda_means,\n",
    "    draw_solution_graph,\n",
    "    brute_force_finding,\n",
    "    calculate_distances_cost\n",
    ")\n",
    "from main.vqaa.vqaa_tools import ( \n",
    "    heuristical_embedding, \n",
    "    atoms_register,\n",
    "    atoms_list, \n",
    "    generate_grid,\n",
    "    run_vqaa,\n",
    "    plot_distribution,\n",
    ")\n",
    "from main.tree.utils import ( \n",
    "    view_linkage_on_map, \n",
    "    draw_centers_on_map,\n",
    "    map_draw_line,\n",
    "    convert_bitstring_to_matrix,\n",
    "    assemble_line,\n",
    "    string_to_bitstring,\n",
    ")\n",
    "from data.utils import fetch_amenities_from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load initial data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks shows the proof-of-concept of the bus line optimization algorithm developed. To start, we must first fetch data from a specific city.\n",
    "In this case, we fetch the data from Granada, Spain. The data consists of local amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load previously stored overpy lat/lon datafile for different amenities\n",
    "filepath = os.path.join('data', 'amenities-granada.csv')\n",
    "if os.path.exists(filepath):\n",
    "    amenities_data = pd.read_csv(filepath)\n",
    "else:\n",
    "    # If there is no previous data:\n",
    "    query_file = os.path.join('data', 'overpy-granada-query.txt')\n",
    "    query = None\n",
    "    with open(query_file) as file:\n",
    "        query = file.read()\n",
    "    amenities_data = fetch_amenities_from(query=query) # Defaults to Granada\n",
    "    amenities_data.to_csv(filepath)\n",
    "# Create a hierarchical clustering of amenities\n",
    "hierarchical_cluster = linkageCut(amenities_data)\n",
    "# Set a specific number of clusters per levels. Max 9 in this POC\n",
    "nclusters = 4\n",
    "levels = 2\n",
    "labels = hierarchical_cluster.top_down_view_recur(nclusters=nclusters, levels=2)\n",
    "# Visualize for debugging purposes.\n",
    "view_linkage_on_map(linkage_matrix=hierarchical_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 0 solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetch the centers of the first level\n",
    "centers = hierarchical_cluster.give_centers_level(0)\n",
    "# Sanity check by drawing the graph\n",
    "draw_centers_on_map(centers, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example we will impose two random nodes as start and endpoints.\n",
    "Say we wanted to connect a marginalized area with another area where public services or/and green spaces are available. These extreme nodes will work as the extremes of the route. Additionally, we will fix for the route to traverse a fixed (p) number of districts (level-0 clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(54)\n",
    "# Fetch the distance from the centers of the first level\n",
    "distances = hierarchical_cluster.dist_matrix_level(0, return_labels=False)\n",
    "# Set initial global parameters\n",
    "N = distances.shape[0]\n",
    "p = 2\n",
    "node_options = set(np.arange(nclusters) + 1)\n",
    "startNode = np.random.choice(list(node_options))\n",
    "endNode = np.random.choice(list(node_options - set([startNode])))\n",
    "print(\"Selected random nodes:\", startNode, endNode)\n",
    "\n",
    "# Process Parameters\n",
    "p = min(p, N-1)\n",
    "startNode = min(startNode, N)\n",
    "endNode = min(endNode, N)\n",
    "\n",
    "reduced_distances = distances/np.max(distances)\n",
    "maxDistance = np.max(reduced_distances)\n",
    "# NOTE: temporary double pardir while we decide the new structure for the lambdas\n",
    "lambda_paths = glob.glob(os.path.join(os.path.pardir, 'data', 'lamdasOptimized', '*'))\n",
    "mean_lambdas = load_lambda_means(lambda_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The general procedure is shown here. First, the QUBO matrix is generated, with constraints penalties optimized for the problem (see docs).\n",
    "Second, we embed the atoms and then we use any of the available emulators to solve the QUBO problem. In this case, we compare the solution with the brute force result. The brute fore solution will only be computed when $N\\cdot p < 15$, since we have to check $2^{N\\cdot p}$ combinations. Then, we can plot the raw result: the number of counts.\n",
    "\n",
    "WARNING: The simulator may explode sometimes giving 0000.. as only counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q_matrix_initial,_ = create_QUBO_matrix(reduced_distances, p, startNode - 1, endNode - 1, mean_lambdas)   \n",
    "if N*(p+1) < 20:\n",
    "    # Getting first solution, the one with lower cost\n",
    "    solution_ref = brute_force_finding(Q_matrix_initial, reduced_distances, p, False)[0][0]\n",
    "    \n",
    "else:\n",
    "    solution_ref, _ = solve_qubo_with_Dwave(Q_matrix_initial, num_reads=1000)\n",
    "print('Our solution reference is:')\n",
    "print(solution_ref)\n",
    "check_solution(string_to_bitstring(solution_ref), N,  p, startNode - 1, endNode - 1)\n",
    "\n",
    "# Creating register and solving VQAA\n",
    "coords = heuristical_embedding(atoms_list(len(Q_matrix_initial)), generate_grid(50, 50,1), Q_matrix_initial)\n",
    "register = atoms_register(coords)\n",
    "# Emulator options: \"qutip\" (pulser), \"mps\", and \"sv\"\n",
    "C_0, x = run_vqaa(Q_matrix_initial, register, \"qutip\")\n",
    "\n",
    "plot_distribution(C_0, 50, \"\".join([str(x) for x in solution_ref]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the set of proposed solutions, the ones with higher counts (in this case, \n",
    "we will take the top 100) we can  verify our imposed QUBO constraints. Furthermore, from our surviving options, we can select the \n",
    "one with lower associated cost in terms of distance: our main objective! We explicitely define the function to highlight its simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_solution(proposed_sols, distances, p):\n",
    "    # Discard solutions that do not fulfill our constraints\n",
    "    constrained = [check_solution_return(string_to_bitstring(sol), N, p, startNode - 1, endNode - 1) for sol in proposed_sols]\n",
    "    # Select the one(s) with lower distance associated cost\n",
    "    distance_costs = np.array([calculate_distances_cost(np.array(string_to_bitstring(sol)), distances, p) for sol in proposed_sols])\n",
    "    print(distance_costs[constrained])\n",
    "    if np.sum(constrained) == 0:\n",
    "        print('NO solution, consider increasing the number of proposed solutions')\n",
    "    return proposed_sols[constrained][np.argmin(distance_costs[constrained])]\n",
    "\n",
    "number_props = len(C_0.keys())\n",
    "print(number_props)\n",
    "C_ = dict(sorted(C_0.items(), key=lambda item: item[1], reverse=True))\n",
    "proposed_sols = np.array(list(C_.keys() ) )[:number_props]\n",
    "level0_sols = get_best_solution(proposed_sols, distances, p) # symmetric matrix means that we are counting distances twice\n",
    "level0_sols = string_to_bitstring(level0_sols)\n",
    "print(\"Found solution:\", level0_sols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adjacency = convert_bitstring_to_matrix(level0_sols, N=N, p=p)\n",
    "map_draw_line(centers[:, ::-1], adjacency, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1 solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formulation with initial lambdas\n",
    "level1_sols = {} # Dict that will hold the bitstring, connected level-0 clusters and corresponding start-end nodes \n",
    "all_indices = set(np.arange(nclusters - 1) + 1)\n",
    "for i in range(1, nclusters+1):\n",
    "    \n",
    "    connections = np.concatenate([adjacency[:,i-1].nonzero()[0], adjacency[i-1, :].nonzero()[0]], axis=0) + 1\n",
    "    print(\"----- Solving level-1:\", i, \"------\\n\")\n",
    "    print(\"connections\", connections)\n",
    "    if len(connections) > 0: #Selected\n",
    "        # Fetch the centers of the first level\n",
    "        distances, closest, _ = hierarchical_cluster.dist_matrix_label_down(\n",
    "        i,\n",
    "        connections=connections,\n",
    "        )\n",
    "        \n",
    "        startNode = None\n",
    "        if len(closest) >= 1:\n",
    "            startNode = closest[0]\n",
    "            choices = all_indices - set([startNode])\n",
    "        if len(closest) == 2:\n",
    "            endNode = closest[1]\n",
    "        else:\n",
    "            endNode = np.random.choice(list(choices)) # POC criterion, better heuristic should be chosen\n",
    "        print(\"Start-end\", startNode, endNode)\n",
    "\n",
    "        Q_matrix_initial,_ = create_QUBO_matrix(reduced_distances, p, startNode - 1, endNode - 1, mean_lambdas)\n",
    "        \n",
    "        # Creating register and solving VQAA\n",
    "        coords = heuristical_embedding(atoms_list(len(Q_matrix_initial)), generate_grid(50, 50,1), Q_matrix_initial)\n",
    "        register = atoms_register(coords)\n",
    "        C_1, x = run_vqaa(Q_matrix_initial, register, \"qutip\")\n",
    "        \n",
    "        # Our ref is Dwave\n",
    "        solution_ref = solve_qubo_with_Dwave(Q_matrix_initial, num_reads=1000)\n",
    "        plot_distribution(C_1, 50, \"\".join([str(x) for x in solution_ref]))\n",
    "        \n",
    "        C_ = dict(sorted(C_1.items(), key=lambda item: item[1], reverse=True))\n",
    "        number_props = len(C_.keys())\n",
    "        proposed_sols = np.array(list(C_.keys() ) )[:number_props]\n",
    "        sol_ =  get_best_solution(proposed_sols, distances, p) # symmetric matrix means that we are counting distances twice\n",
    "        print(\"Proposed solution bitstring:\")\n",
    "        print(sol_)\n",
    "        sol_ = string_to_bitstring(sol_)\n",
    "        level1_sols[i] = [sol_, closest]\n",
    "        \n",
    "    else:\n",
    "        level1_sols[i] = (np.zeros((nclusters*(p + 1))), [])\n",
    "        print('The line does not cross this level-0 cluster')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how one route at level 1 looks like. Feel free to try different example_indx. The clusters where the line is defined are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.nonzero(np.array(level0_sols).reshape(p+1, N))[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_indx = 2\n",
    "example_centers = hierarchical_cluster.give_centers_label_down(example_indx)\n",
    "example_adj = convert_bitstring_to_matrix(level1_sols[example_indx][0],N=nclusters, p=p)\n",
    "map = map_draw_line(centers[:, ::-1], adjacency, color='red')\n",
    "map_draw_line(example_centers[:, ::-1], example_adj, color='blue', map=map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's piece all the information about the calculated lines at level 1 together using what we know about the connections at level 0. Effectively creating a unified route.\n",
    "\n",
    "How do we join all these disconnected level-1 mini-routes? The larger-scale route is given by the level 0. We know that 1 should be connected with 2, then we can connect the closest (driving distance) clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembled = assemble_line(np.array(level0_sols),level1_sols, nclusters, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centers_level1 = hierarchical_cluster.give_centers_level(1)\n",
    "map_draw_line(centers_level1[:,::-1], assembled, color='blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
